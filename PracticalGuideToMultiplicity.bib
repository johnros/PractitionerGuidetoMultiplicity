%% This BibTeX bibliography file was created using BibDesk.
%% http://bibdesk.sourceforge.net/


%% Created for Jonathan Rosenblatt at 2013-03-12 01:44:45 +0200 


%% Saved with string encoding Unicode (UTF-8) 



@book{lazar_statistical_2008,
	Author = {Lazar, Nicole A.},
	Edition = {1},
	Isbn = {0387781900},
	Month = jul,
	Publisher = {Springer},
	Title = {The Statistical Analysis of Functional {MRI} Data},
	Year = {2008}}

@article{efron_microarrays_2008,
	Author = {Efron, B.},
	File = {Google Scholar Linked Page:/Users/jonathanrosenblatt/Library/Application Support/Zotero/Profiles/j3mouxo1.default/zotero/storage/TVFE4XQ7/DPubS.html:text/html},
	Keywords = {Bayesian Inference, {FDR}, Microarray},
	Number = {1},
	Pages = {1--22},
	Title = {Microarrays, empirical Bayes and the two-groups model},
	Volume = {23},
	Year = {2008}}

@article{farcomeni_review_2008,
	Abstract = {In the last decade a growing amount of statistical research has been devoted to multiple testing, motivated by a variety of applications in medicine, bioinformatics, genomics, brain imaging, etc. Research in this area is focused on developing powerful procedures even when the number of tests is very large. This paper attempts to review research in modern multiple hypothesis testing with particular attention to the false discovery proportion, loosely defined as the number of false rejections divided by the number of rejections. We review the main ideas, stepwise and augmentation procedures; and resampling based testing. We also discuss the problem of dependence among the test statistics. Simulations make a comparison between the procedures and with Bayesian methods. We illustrate the procedures in applications in {DNA} microarray data analysis. Finally, few possibilities for further research are highlighted.},
	Author = {Farcomeni, Alessio},
	Date-Modified = {2013-03-11 23:44:19 +0000},
	File = {Snapshot:/Users/jonathanrosenblatt/Library/Application Support/Zotero/Profiles/j3mouxo1.default/zotero/storage/T6C2J7W3/347.html:text/html},
	Issn = {0962-2802, 1477-0334},
	Journal = {Stat Methods Med Res},
	Language = {en},
	Month = aug,
	Number = {4},
	Pages = {347--388},
	Title = {A review of modern multiple hypothesis testing, with particular attention to the false discovery proportion},
	Urldate = {2013-03-07},
	Volume = {17},
	Year = {2008},
	Bdsk-Url-1 = {http://smm.sagepub.com/content/17/4/347},
	Bdsk-Url-2 = {http://dx.doi.org/10.1177/0962280206079046}}

@article{benjamini_john_2002,
	Abstract = {This article provides a historical overview of the philosophical, theoretical and practical contributions made by John Tukey to the field of simultaneous inference. His early work, culminating in the monograph {"The} Problem of Multiple Comparisons," established him as one of the pioneers in the field, investing it with both academic respectability and a focus on practical problems. For many years afterward, Tukey only published sporadically in the area but remained convinced that multiplicity issues were of fundamental importance. During the last decade of his life, Tukey again devoted substantial attention to multiplicity, experimenting with different graphical representations of multiple comparison procedures and exploring the implications of new approaches to controlling family-wise error rates. He leaves a rich legacy that should engage and inspire statisticians for many years to come.},
	Author = {Benjamini, Yoav and Braun, Henry},
	Date-Modified = {2013-03-11 23:44:19 +0000},
	File = {euclid.aos.1043351247.pdf:/Users/jonathanrosenblatt/Library/Application Support/Zotero/Profiles/j3mouxo1.default/zotero/storage/2N47AVA4/euclid.aos.1043351247.pdf:application/pdf;John W. Tukey's Contributions to Multiple Comparisons:/Users/jonathanrosenblatt/Library/Application Support/Zotero/Profiles/j3mouxo1.default/zotero/storage/58JREVRC/1558730.html:text/html;JSTOR Full Text PDF:/Users/jonathanrosenblatt/Library/Application Support/Zotero/Profiles/j3mouxo1.default/zotero/storage/BGPS27N9/Benjamini and Braun - 2002 - John W Tukey's Contributions to Multiple Comparis.pdf:application/pdf},
	Issn = {00905364},
	Keywords = {People},
	Month = dec,
	Note = {{ArticleType:} primary\_article / Full publication date: Dec., 2002 / Copyright {\textcopyright} 2002 Institute of Mathematical Statistics},
	Number = {6},
	Pages = {1576--1594},
	Title = {John W. Tukey's Contributions to Multiple Comparisons},
	Urldate = {2009-07-01},
	Volume = {30},
	Year = {2002},
	Bdsk-Url-1 = {http://www.jstor.org/stable/1558730},
	Bdsk-Url-2 = {http://dx.doi.org/10.2307/1558730}}

@article{benjamini_adjusting_2011,
	Abstract = {In many large multiple testing problems the hypotheses are divided into families. Given the data, families with evidence for true discoveries are selected, and hypotheses within them are tested. Neither controlling the error-rate in each family separately nor controlling the error-rate over all hypotheses together can assure that an error-rate is controlled in the selected families. We formulate this concern about selective inference in its generality, for a very wide class of error-rates and for any selection criterion, and present an adjustment of the testing level inside the selected families that retains the average error-rate over the selected families.},
	Author = {Benjamini, Yoav and Bogomolov, Marina},
	Date-Modified = {2013-03-11 23:44:19 +0000},
	File = {1106.3670 PDF:/Users/jonathanrosenblatt/Library/Application Support/Zotero/Profiles/j3mouxo1.default/zotero/storage/D3X5UR93/Benjamini and Bogomolov - 2011 - Adjusting for selection bias in testing multiple f.pdf:application/pdf;arXiv.org Snapshot:/Users/jonathanrosenblatt/Library/Application Support/Zotero/Profiles/j3mouxo1.default/zotero/storage/DFI9I8N2/1106.html:text/html},
	Keywords = {Mathematics - Statistics Theory},
	Month = jun,
	Title = {Adjusting for selection bias in testing multiple families of hypotheses},
	Urldate = {2011-11-13},
	Year = {2011},
	Bdsk-Url-1 = {http://arxiv.org/abs/1106.3670}}

@article{storey_direct_2002,
	Abstract = {{Summary.Multiple-hypothesis} testing involves guarding against much more complicated errors than single-hypothesis testing. Whereas we typically control the type I error rate for a single-hypothesis test, a compound error rate is controlled for multiple-hypothesis tests. For example, controlling the false discovery rate {FDR} traditionally involves intricate sequential p-value rejection methods based on the observed data. Whereas a sequential p-value method fixes the error rate and estimates its corresponding rejection region, we propose the opposite approach2014we fix the rejection region and then estimate its corresponding error rate. This new approach offers increased applicability, accuracy and power. We apply the methodology to both the positive false discovery rate {pFDR} and {FDR}, and provide evidence for its benefits. It is shown that {pFDR} is probably the quantity of interest over {FDR.} Also discussed is the calculation of the q-value, the {pFDR} analogue of the p-value, which eliminates the need to set the error rate beforehand as is traditionally done. Some simple numerical examples are presented that show that this new approach can yield an increase of over eight times in power compared with the {Benjamini2013Hochberg} {FDR} method.},
	Author = {Storey, John D.},
	Date-Modified = {2013-03-11 23:44:19 +0000},
	File = {Full Text PDF:/Users/jonathanrosenblatt/Library/Application Support/Zotero/Profiles/j3mouxo1.default/zotero/storage/UMBWJ8RR/Storey - 2002 - A direct approach to false discovery rates.pdf:application/pdf;Snapshot:/Users/jonathanrosenblatt/Library/Application Support/Zotero/Profiles/j3mouxo1.default/zotero/storage/7N5I84RV/full.html:text/html;Wiley Interscience PDF:/Users/jonathanrosenblatt/Library/Application Support/Zotero/Profiles/j3mouxo1.default/zotero/storage/EAI7QWEU/fulltext.pdf:application/pdf},
	Keywords = {False discovery rate, {FDR}, Multiple comparisons, p-values, {pFDR}, Positive false discovery rate, q-values, qvalue, Sequential p-value methods, Simultaneous inference, Statistics},
	Number = {3},
	Pages = {479--498},
	Title = {A direct approach to false discovery rates},
	Urldate = {2009-02-23},
	Volume = {64},
	Year = {2002},
	Bdsk-Url-1 = {http://dx.doi.org/10.1111/1467-9868.00346}}

@misc{r_development_core_team_r:_2011,
	Author = {{R Development Core Team}},
	Date-Modified = {2013-03-11 23:44:19 +0000},
	File = {R FAQ:/Users/jonathanrosenblatt/Library/Application Support/Zotero/Profiles/j3mouxo1.default/zotero/storage/8PKBMGVJ/R-FAQ.html:text/html},
	Howpublished = {{http://www.R-project.org}},
	Title = {R: A Language and Environment for Statistical Computing},
	Urldate = {2011-05-01},
	Year = {2011},
	Bdsk-Url-1 = {http://www.R-project.org}}

@article{stein_voxelwise_2010,
	Abstract = {The structure of the human brain is highly heritable, and is thought to be influenced by many common genetic variants, many of which are currently unknown. Recent advances in neuroimaging and genetics have allowed collection of both highly detailed structural brain scans and genome-wide genotype information. This wealth of information presents a new opportunity to find the genes influencing brain structure. Here we explore the relation between 448,293 single nucleotide polymorphisms in each of 31,622 voxels of the entire brain across 740 elderly subjects (mean age\&\#xa0;{\^A}{\textpm}\&\#xa0;s.d.: 75.52\&\#xa0;{\^A}{\textpm}\&\#xa0;6.82{\^A}~years; 438 male) including subjects with Alzheimer's disease, Mild Cognitive Impairment, and healthy elderly controls from the Alzheimer's Disease Neuroimaging Initiative ({ADNI).} We used tensor-based morphometry to measure individual differences in brain structure at the voxel level relative to a study-specific template based on healthy elderly subjects. We then conducted a genome-wide association at each voxel to identify genetic variants of interest. By studying only the most associated variant at each voxel, we developed a novel method to address the multiple comparisons problem and computational burden associated with the unprecedented amount of data. No variant survived the strict significance criterion, but several genes worthy of further exploration were identified, including {CSMD2} and {CADPS2.} These genes have high relevance to brain structure. This is the first voxelwise genome wide association study to our knowledge, and offers a novel method to discover genetic influences on brain structure.},
	Author = {Stein, Jason L. and Hua, Xue and Lee, Suh and Ho, April J. and Leow, Alex D. and Toga, Arthur W. and Saykin, Andrew J. and Shen, Li and Foroud, Tatiana and Pankratz, Nathan and Huentelman, Matthew J. and Craig, David W. and Gerber, Jill D. and Allen, April N. and Corneveaux, Jason J. and {DeChairo}, Bryan M. and Potkin, Steven G. and Weiner, Michael W. and M. Thompson, Paul},
	Date-Modified = {2013-03-11 23:44:19 +0000},
	File = {ScienceDirect Full Text PDF:/Users/jonathanrosenblatt/Library/Application Support/Zotero/Profiles/j3mouxo1.default/zotero/storage/NKKA5CZJ/Stein et al. - 2010 - Voxelwise genome-wide association study (vGWAS).pdf:application/pdf;ScienceDirect Snapshot:/Users/jonathanrosenblatt/Library/Application Support/Zotero/Profiles/j3mouxo1.default/zotero/storage/KVWMHVHD/S1053811910002004.html:text/html},
	Issn = {1053-8119},
	Month = nov,
	Number = {3},
	Pages = {1160--1174},
	Title = {Voxelwise genome-wide association study ({vGWAS)}},
	Urldate = {2011-11-13},
	Volume = {53},
	Year = {2010},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S1053811910002004},
	Bdsk-Url-2 = {http://dx.doi.org/10.1016/j.neuroimage.2010.02.032}}

@article{tukey_philosophy_1991,
	Abstract = {This paper is based on the 1989 Miller Memorial Lecture at Stanford University. The topic was chosen because of Rupert Miller's long involvement and significant contributions to multiple comparison procedures and theory. Our emphasis will be on the major questions that have received relatively little attention--on what one wants multiple comparisons to do, on why one wants to do that, and on how one can communicate the results. Very little attention will be given to how the results can be calculated--after all, there are books about that (e.g., Miller, 1966, 1981; Hochberg and Tamhane, 1987).},
	Author = {Tukey, John W.},
	Date-Modified = {2013-03-11 23:44:19 +0000},
	File = {Euclid Project PDF:/Users/jonathanrosenblatt/Library/Application Support/Zotero/Profiles/j3mouxo1.default/zotero/storage/MHJUPEID/DPubS.html:text/html;euclid.ss.1177011945.pdf:/Users/jonathanrosenblatt/Library/Application Support/Zotero/Profiles/j3mouxo1.default/zotero/storage/D5HP4Q8Z/euclid.ss.1177011945.pdf:application/pdf},
	Keywords = {Philosophy, Statistics},
	Number = {1},
	Pages = {100--116},
	Title = {The Philosophy of Multiple Comparisons},
	Urldate = {2009-07-01},
	Volume = {6},
	Year = {1991},
	Bdsk-Url-1 = {http://projecteuclid.org/DPubS?verb=Display&version=1.0&service=UI&handle=euclid.ss/1177011945&page=record}}

@book{westfall_multiple_2011,
	Abstract = {New and extensively updated for {SAS} 9 and later! Have you ever felt that there was no multiple inference method that fit the particular constraints of your data? Or been overwhelmed by the many choices of procedures? Multiple Comparisons and Multiple Tests Using {SAS}, Second Edition, written by Peter Westfall, Randall Tobias, and Russell Wolfinger, solves both problems for you by providing cutting-edge methods, specialized macros, and proven "best bet" procedures. The specialized macros and dozens of real-world examples illustrate solutions for a broad variety of problems that call for multiple inferences. The book also discusses the pitfalls and advantages of various methods, thereby helping you decide which is the most appropriate for your purposes. If you are a researcher or scientist in pharmaceuticals, engineering, government, or medicine, you will find many methods applied to real data and examples from your field. The book includes specialized code and explanations throughout. It discusses in detail pairwise comparisons and comparisons with a control. Additional topics include general linear contrasts; multiple comparisons of multivariate means; and multiple inferences with mixed models, discrete data, and survival analysis.},
	Author = {Westfall, Peter H. and Tobias, R. Randall Davis and Wolfinger, Russell Dean},
	Isbn = {9781607648857},
	Keywords = {Computers / Mathematical \& Statistical Software, Mathematics / Probability \& Statistics / General},
	Language = {en},
	Month = aug,
	Publisher = {{SAS} Institute},
	Title = {Multiple Comparisons and Multiple Tests Using {SAS}, Second Edition},
	Year = {2011}}

@article{van_der_laan_augmentation_2004,
	Abstract = {This article shows that any single-step or stepwise multiple testing procedure (asymptotically) controlling the family-wise error rate ({FWER)} can be augmented into procedures that (asymptotically) control tail probabilities for the number of false positives and the proportion of false positives among the rejected hypotheses. Specifically, given any procedure that (asymptotically) controls the {FWER} at level alpha, we propose simple augmentation procedures that provide (asymptotic) level-alpha control of: (i) the generalized family-wise error rate, i.e., the tail probability, {gFWER(k)}, that the number of Type I errors exceeds a user-supplied integer k, and (ii) the tail probability, {TPPFP(q)}, that the proportion of Type I errors among the rejected hypotheses exceeds a user-supplied value 0{\textless}q{\textless}1. Existing approaches for control of the proportion of false positives typically rely on the assumption that the test statistics are independent, while our proposed augmentation procedures control the {gFWER} and {TPPFP} for general data generating distributions, with arbitrary dependence structures among variables. Applying the augmentation methods to step-down multiple testing procedures that control the {FWER} asymptotically exactly at level alpha (van der Laan et al., 2004), yields procedures that also provide exact asymptotic control of the {gFWER} and {TPPFP} at level alpha. The adjusted p-values for the {gFWER} and {TPPFP-controlling} augmentation procedures are shown to be simple functions of the adjusted p-values for the original {FWER-controlling} procedure. Finally, two simple conservative procedures are proposed for controlling the false discovery rate.},
	Author = {van der Laan, Mark J and Dudoit, Sandrine and Pollard, Katherine S},
	Date-Modified = {2013-03-11 23:44:19 +0000},
	Issn = {1544-6115},
	Journal = {Stat Appl Genet Mol Biol},
	Note = {{PMID:} 16646793},
	Pages = {Article15},
	Title = {Augmentation procedures for control of the generalized family-wise error rate and tail probabilities for the proportion of false positives},
	Volume = {3},
	Year = {2004},
	Bdsk-Url-1 = {http://dx.doi.org/10.2202/1544-6115.1042}}

@article{benjamini_controlling_1995,
	Abstract = {The common approach to the multiplicity problem calls for controlling the familywise error rate ({FWER).} This approach, though, has faults, and we point out a few. A different approach to problems of multiple significance testing is presented. It calls for controlling the expected proportion of falsely rejected hypotheses-the false discovery rate. This error rate is equivalent to the {FWER} when all hypotheses are true but is smaller otherwise. Therefore, in problems where the control of the false discovery rate rather than that of the {FWER} is desired, there is potential for a gain in power. A simple sequential Bonferroni-type procedure is proved to control the false discovery rate for independent test statistics, and a simulation study shows that the gain in power is substantial. The use of the new procedure and the appropriateness of the criterion are illustrated with examples.},
	Author = {Benjamini, Yoav and Hochberg, Yosef},
	Copyright = {Copyright {\textcopyright} 1995 Royal Statistical Society},
	Date-Modified = {2013-03-11 23:44:19 +0000},
	File = {JSTOR Full Text PDF:/Users/jonathanrosenblatt/Library/Application Support/Zotero/Profiles/j3mouxo1.default/zotero/storage/D5FV8QSI/Benjamini and Hochberg - 1995 - Controlling the False Discovery Rate A Practical .pdf:application/pdf},
	Issn = {0035-9246},
	Journal = {Journal of the Royal Statistical Society. Series B (Methodological)},
	Month = jan,
	Note = {{ArticleType:} research-article / Full publication date: 1995 / Copyright {\textcopyright} 1995 Royal Statistical Society},
	Number = {1},
	Pages = {289--300},
	Shorttitle = {Controlling the False Discovery Rate},
	Title = {Controlling the False Discovery Rate: A Practical and Powerful Approach to Multiple Testing},
	Urldate = {2013-03-07},
	Volume = {57},
	Year = {1995},
	Bdsk-Url-1 = {http://www.jstor.org/stable/2346101},
	Bdsk-Url-2 = {http://dx.doi.org/10.2307/2346101}}

@article{genovese_exceedance_2006,
	Author = {Genovese, Christopher R and Wasserman, Larry},
	Date-Modified = {2013-03-11 23:44:19 +0000},
	File = {American Statistical Association Portal :: Exceedance Control of the False Discovery Proportion - Journal of the American Statistical Association - Volume 101, Issue 476:/Users/jonathanrosenblatt/Library/Application Support/Zotero/Profiles/j3mouxo1.default/zotero/storage/7X7Q2C93/016214506000000339.html:text/html},
	Issn = {0162-1459, 1537-{274X}},
	Month = dec,
	Number = {476},
	Pages = {1408--1417},
	Title = {Exceedance Control of the False Discovery Proportion},
	Urldate = {2013-03-07},
	Volume = {101},
	Year = {2006},
	Bdsk-Url-1 = {http://amstat.tandfonline.com/doi/abs/10.1198/016214506000000339},
	Bdsk-Url-2 = {http://dx.doi.org/10.1198/016214506000000339}}

@article{benjamini_discovering_2010,
	Abstract = {I describe the background for the paper {'Controlling} the false discovery rate: a new and powerful approach to multiple comparisons' by Benjamini and Hochberg that was published in the Journal of the Royal Statistical Society, Series B, in 1995. I review the progress since made on the false discovery rate, as well as the major conceptual developments that followed. {\textcopyright} 2010 Royal Statistical Society.},
	Author = {Benjamini, Y.},
	Date-Modified = {2013-03-11 23:44:19 +0000},
	Issn = {13697412},
	Keywords = {{'Testimation'}, False coverage rate, Multiple comparisons},
	Language = {English},
	Number = {4},
	Pages = {405--416},
	Title = {Discovering the false discovery rate},
	Volume = {72},
	Year = {2010},
	Bdsk-Url-1 = {http://dx.doi.org/10.1111/j.1467-9868.2010.00746.x}}

@article{sun_oracle_2007,
	Author = {Sun, Wenguang and Cai, T. Tony},
	Date-Modified = {2013-03-11 23:44:19 +0000},
	File = {American Statistical Association Portal :: Oracle and Adaptive Compound Decision Rules for False Discovery Rate Control - Journal of the American Statistical Association - Volume 102, Issue 479:/Users/jonathanrosenblatt/Library/Application Support/Zotero/Profiles/j3mouxo1.default/zotero/storage/QMG8JTA3/016214507000000545.html:text/html},
	Issn = {0162-1459, 1537-{274X}},
	Month = sep,
	Number = {479},
	Pages = {901--912},
	Title = {Oracle and Adaptive Compound Decision Rules for False Discovery Rate Control},
	Urldate = {2012-07-04},
	Volume = {102},
	Year = {2007},
	Bdsk-Url-1 = {http://amstat.tandfonline.com/doi/abs/10.1198/016214507000000545},
	Bdsk-Url-2 = {http://dx.doi.org/10.1198/016214507000000545}}

@article{benjamini_simultaneous_2010,
	Abstract = {The previous decade can be viewed as a second golden for era Multiple Comparisons research. I argue that much of the success stems from our being able to address real current needs. At the same time, this success generated a plethora of concepts for error rate and power, as well as multiplicity of methods for addressing them. These confuse the users of our methodology and pose a threat. To avoid the threat, it is our responsibility to match our theoretical goals to the goals of the users of statistics. Only then should we match the methods to the theoretical goals. Considerations related to such needs are discussed: simultaneous inference or selective inference, testing or estimation, decision making or scientific reporting. I then further argue that the vitality of our field in the future {\textendash} as a research area {\textendash} depends upon our ability to continue and address the real needs of statistical analyses in current problems. Two application areas offering new challenges have received less attention in our community to date are discussed. Safety analysis in clinical trials, where I offer an aggregated safety assessment methodology and functional Magnetic Resonance Imaging.},
	Author = {Benjamini, Yoav},
	Copyright = {Copyright {\textcopyright} 2010 {WILEY-VCH} Verlag {GmbH} \& Co. {KGaA}, Weinheim},
	Date-Modified = {2013-03-11 23:44:19 +0000},
	File = {Full Text PDF:/Users/jonathanrosenblatt/Library/Application Support/Zotero/Profiles/j3mouxo1.default/zotero/storage/HP8FT2XQ/Benjamini - 2010 - Simultaneous and selective inference Current succ.pdf:application/pdf;Snapshot:/Users/jonathanrosenblatt/Library/Application Support/Zotero/Profiles/j3mouxo1.default/zotero/storage/IJN4FMNA/full.html:text/html},
	Issn = {1521-4036},
	Keywords = {Aggregated safety analysis, False discovery rates, Familywise error rate, Functional Magnetic Resonance Imaging, Multiple comparisons procedures},
	Language = {en},
	Number = {6},
	Pages = {708{\textendash}721},
	Shorttitle = {Simultaneous and selective inference},
	Title = {Simultaneous and selective inference: Current successes and future challenges},
	Urldate = {2013-03-11},
	Volume = {52},
	Year = {2010},
	Bdsk-Url-1 = {http://onlinelibrary.wiley.com/doi/10.1002/bimj.200900299/abstract},
	Bdsk-Url-2 = {http://dx.doi.org/10.1002/bimj.200900299}}

@article{donoho_higher_2004,
	Abstract = {Higher criticism, or second-level significance testing, is a multiple-comparisons concept mentioned in passing by Tukey. It concerns a situation where there are many independent tests of significance and one is interested in rejecting the joint null hypothesis. Tukey suggested comparing the fraction of observed significances at a given alpha-level to the expected fraction under the joint null. In fact, he suggested standardizing the difference of the two quantities and forming a z-score; the resulting z-score tests the significance of the body of significance tests.   We consider a generalization, where we maximize this z-score over a range of significance levels 0 {\textless} \&alpha; {\&LE;} \&alpha;(0). We are able to show that the resulting higher critic-ism statistic is effective at resolving a very subtle testing problem: testing whether n normal means are all zero versus the alternative that a small fraction is nonzero.   The subtlety of this "sparse normal means" testing problem can be seen from work of Ingster and Jin, who studied such problems in great detail. In their Studies, they identified an interesting range of cases where the small fraction of nonzero means is so small that the alternative hypothesis exhibits little noticeable effect on the distribution of the p-values either for the bulk of the tests or for the few most highly significant tests. In this range, when the amplitude of nonzero means is calibrated with the fraction of nonzero means, the likelihood ratio test for a precisely specified alternative would still succeed in separating the two hypotheses.   We show that the higher criticism is successful throughout the same region of amplitude sparsity where the likelihood ratio test would succeed. Since it does not require a specification of the alternative, this shows that higher criticism is in a sense optimally adaptive to unknown sparsity and size of the nonnull effects. While our theoretical work is largely asymptotic, we provide Simulations in finite samples and suggest some possible applications. We also show that higher critcism works well over a range of non-Gaussian cases.},
	Author = {Donoho, D. and Jin, J. S.},
	Date-Modified = {2013-03-11 23:44:19 +0000},
	Issn = {0090-5364},
	Journal = {Ann. Stat.},
	Language = {English},
	Month = jun,
	Note = {{WOS:000221981400005}},
	Number = {3},
	Pages = {962--994},
	Title = {Higher criticism for detecting sparse heterogeneous mixtures},
	Volume = {32},
	Year = {2004},
	Bdsk-Url-1 = {http://dx.doi.org/10.1214/009053604000000265}}

@book{poldrack_handbook_2011,
	Author = {Poldrack, Russell A. and Mumford, Jeanette A. and Nichols, Thomas E.},
	Edition = {1},
	Isbn = {0521517664},
	Month = aug,
	Publisher = {Cambridge University Press},
	Title = {Handbook of Functional {MRI} Data Analysis},
	Year = {2011}}
